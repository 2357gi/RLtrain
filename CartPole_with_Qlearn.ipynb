{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qlearnを用いてCartPoleをする\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動画の描画関数の宣言\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \n",
    "    plt.figure(figsize=(frames[0].shape[1]/72.0, frames[0].shape[0]/72.0), dpi=72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "    \n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames),\n",
    "                                  interval=50)\n",
    "    \n",
    "    anim.save('movie_cartpole.mp4')\n",
    "    display(display_animation(anim, default_mode=\n",
    "                             'loop'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 状態の定義\n",
    "ENV = 'CartPole-v0'\n",
    "NUM_DIZITIZED = 6  # 離散化分割数\n",
    "GAMMA = 0.99  # 時間割引率 \n",
    "ETA = 0.5  # 学習係数\n",
    "MAX_STEPS = 200  # 1試行の最大step数\n",
    "MAX_EPISODES = 1000  # 最大試行回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"cartpoleの棒突き台車そのもの\"\"\"\n",
    "    \n",
    "    \n",
    "    def __int__(self, num_status, num_actions):\n",
    "        self.brain = Brain(num_status, num_actions)  # エージェントが行動を選択するためのBrainを生成。\n",
    "    \n",
    "    \n",
    "    def update_Q_function(self, observation, action, reward, observation_next):\n",
    "        \"\"\"Q関数の更新\"\"\"\n",
    "        self.brain.update_Q_table(observation, action, reward, observation_next)\n",
    "    \n",
    "    \n",
    "    def get_action(self, observation, step):\n",
    "        self.brain.decide_action\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    \"\"\"エージェントがもつ脳。行動の決定、Q学習を実行する\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, num_status, num_actions):\n",
    "        self.actions = num_actions  # 行動を取得。　今回はcartpoleであり、右に押すか左に押すかの２選\n",
    "        \n",
    "        self.q_table = np.random.uniform(low=0, high=1, size=(\n",
    "        NUM_DIZITIZED**num_status, num_actions))\n",
    "        \n",
    "        \n",
    "    def bins(self, clip_max, clip_min, num):\n",
    "        return np.linspace(clip_min, clip_max, num+1)[1:-1]\n",
    "    \n",
    "    \n",
    "    def digit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
