{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarsaによる価値反復法の実装\n",
    "- 価値反復法には報酬の概念が必要。\n",
    "- 時刻tでもらえる報酬を$R_t$とし、**即時報酬**と呼ぶ。\n",
    "- また、今後未来でもらえる報酬の合計を報酬和と呼ぶ\n",
    "$$\n",
    "G_t = R_{t+1} + R_{t+2} + ...\n",
    "$$\n",
    "となる。\n",
    "- また、時間が経つにつれ報酬の価値は低下する必要がある(報酬の価値が時間の経過につれ低下していく)\n",
    "- よって、時間により報酬の低下を加味した報酬和を設定する必要がある。\n",
    "$$\n",
    "G_t = R_{t+1} + γR_{t+2} + γ^{2}R_{t+3} + ...\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迷路問題にも価値という概念を実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在エージェントがS7にいると仮定し（状態:s = 7）, 行動:a = 右 であればS7→S8と移動することによりゴールすることができる。\n",
    "##### 行動価値関数\n",
    "行動価値関数$Q^π (s, a)$と表される。\n",
    "右へ移動するのはインデックスがa = 1の時なので、\n",
    "$$\n",
    "Q^π (s = 7, a = 1) = R_{t+1} = 1\n",
    "$$\n",
    "となる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆に、a=0,つまりエージェントが上にいく行動をとるときの価値を考えると、そこから最短でゴールするまでS7-S4-S7-S8と2step余計に時間がかかる。\n",
    "つまり、\n",
    "$$\n",
    "Q^π (s = 7, a = 0) = γ^2 * 1\n",
    "$$\n",
    "となる。つまり、時間分だけ割引いた価値がその行動(S7から上に移動する)にはあると考えれる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 状態価値関数\n",
    "**ベルマン方程式をあとでホワイトボードに書きながら分解する!!!**\n",
    "→した\n",
    "![ベルマン方程式](bellman_equation.jpg \"マルコフ決定過程のおまけ付き\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarsa.ipynb               meiro.ipynb               readme.md\r\n",
      "bellman_equation.jpg      meiro_with_softmax.ipynb  requirement.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 価値反復法をSarsaで実装する！\n",
    "今回はQではなくまずはSarsaで。サルサ！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/2357gi/Sandbox/signatej/venv/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# まずはマップとtheta_0の定義。\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 初期状態での迷路の様子_\n",
    "\n",
    "# 図を描く大きさと、図の変数を宣言。\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# make wall\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "# make points\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "# 描画範囲の設定とメモリを消す設定\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis='both', which='both', bottom='off', top='off',\n",
    "                labelbottom='off', right='off', left='off', labelleft='off')\n",
    "\n",
    "# 現在地に丸を描画する。\n",
    "line, = ax.plot([0.5], [2.5], 'o', color = 'g', markersize=60)\n",
    "\n",
    "# 初期の方策を決定するparams theta_0を設定\n",
    "\n",
    "# 行は0~7, 列は移動方向で上右下左を表す。\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],  \n",
    "                   [np.nan, 1, np.nan, 1],\n",
    "                    [np.nan, np.nan, 1, 1],\n",
    "                   [1, 1, 1, np.nan],        \n",
    "                   [np.nan, np.nan, 1, 1],   \n",
    "                   [1, np.nan, np.nan, np.nan],  \n",
    "                   [1, np.nan, np.nan, np.nan],  \n",
    "                   [1, 1, np.nan, np.nan],       \n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期の行動価値関数Qを設定。\n",
    "# 最初はランダムでパラメータを定義、theta_0をかけてnanを反映する。\n",
    "\n",
    "[a, b] = theta_0.shape\n",
    "Q = np.random.rand(a, b) * theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方策パラメータthetaを割合の方策piに変換する関数の定義\n",
    "# 割合にすることで、行動がランダムになる\n",
    "\n",
    "\n",
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    \"\"\"単純に割合を計算する\"\"\"\n",
    "    \n",
    "    [m, n] = theta.shape  # thetaの行列サイズを取得\n",
    "    pi = np.zeros((m, n))\n",
    "    for i in range(0, m):\n",
    "        pi[i, :] = theta[i, :] / np.nansum(theta[i, :])  # 割合の計算\n",
    "    \n",
    "    pi = np.where( np.isnan(pi),0,pi)\n",
    "    \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[       nan 0.04458249 0.1969031         nan]\n",
      " [       nan 0.12721807        nan 0.25182032]\n",
      " [       nan        nan 0.24675234 0.28179087]\n",
      " [0.95338412 0.33280038 0.1701429         nan]\n",
      " [       nan        nan 0.18416732 0.80340313]\n",
      " [0.73037078        nan        nan        nan]\n",
      " [0.95218799        nan        nan        nan]\n",
      " [0.46011592 0.00095397        nan        nan]]\n",
      "--------------------\n",
      "hogehoge[       nan 0.12721807        nan 0.25182032]\n",
      "hogehogehoge3\n",
      "--------------------\n",
      "[[0.         0.5        0.5        0.        ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.         0.         0.5        0.5       ]\n",
      " [0.33333333 0.33333333 0.33333333 0.        ]\n",
      " [0.         0.         0.5        0.5       ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.5        0.5        0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Q)\n",
    "print('-'*20)\n",
    "print('hogehoge' + str(Q[1,:]))\n",
    "print('hogehogehoge' + str(np.nanargmax(Q[1, :])))\n",
    "print('-'*20)\n",
    "print(pi_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ε- greedy法\n",
    "- 一定確率(ε)でランダムに動き、(1-ε)でQの最大値の行動をとる。\n",
    "- これにより、例えば初期段階でのランダムによるゴールで0-1-0-3-4-7-8と行動をとったとすると、\n",
    "一度とった1の行動も有効なものだと捉えられ、1を踏まえた行動をしてしまうことがある。\n",
    "- それを防ぐため、定期的にランダムな行動を行い、最適な行動を探索する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ε- greedy法を実装\n",
    "def get_action(s, Q, eqsilon, pi_0):\n",
    "    direction = ['up', 'right', 'down', 'left']\n",
    "    \n",
    "    # 行動を決める\n",
    "    if np.random.rand() < epsilon:\n",
    "        # εの確率でランダムに動く\n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else:\n",
    "        # Qの最大値の行動を採用する\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "    \n",
    "    if next_direction == 'up':\n",
    "        action = 0\n",
    "    elif next_direction == 'right':\n",
    "        action = 1\n",
    "    elif next_direction == 'down':\n",
    "        action = 2\n",
    "    elif next_direction == 'left':\n",
    "        action = 3\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_next(s, a, Q, epsilon, pi_0):\n",
    "    direction = ['up', 'right', 'down', 'left']\n",
    "    next_direction = direction[a]  # 行動aの方向\n",
    "    \n",
    "    \n",
    "    # 行動から次の状態を決める\n",
    "    if next_direction == 'up':\n",
    "        s_next = s - 3\n",
    "    if next_direction == 'right':\n",
    "        s_next = s + 1\n",
    "    if next_direction == 'down':\n",
    "        s_next = s + 3\n",
    "    if next_direction == 'left':\n",
    "        s_next = s - 1\n",
    "        \n",
    "    return s_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 行動価値関数Q(s, a)をSarsaで更新\n",
    "- Qが正しい値になるように更新学習する部分。\n",
    "- Qが正しい値としてもとまっていればベルマン方程式により\n",
    "$$\n",
    "Q(s_t, a_t) = R_{t+1} + γQ(s_{t+1}, a_{t+1})\n",
    "$$\n",
    "という関係式が整理するが、学習の途中ではQは正しい値としても止まっていないため、この式は成立しない。\n",
    "\n",
    "この時の両辺の差を**TD誤差**と呼ぶ。\n",
    "- この誤差が0になれば、きちんと行動価値関数Qが学習できたことになる！\n",
    "#### Qの更新式を定義する\n",
    "$$\n",
    "Q(s_t, a_t) = Q(s_t, a_t) + η*(R_{t+1} + γQ(s_{t+1}, a_{t+1}) - Q(s_t, a_t))\n",
    "$$\n",
    "**この更新式に従うアルゴリズムをSarsaと呼ぶ！**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsaによる行動価値関数Qの更新\n",
    "\n",
    "\n",
    "def Sarsa(s, a, r, s_next, a_next, Q, eta, gamma):\n",
    "    \n",
    "    if s_next == 8:  # ゴールした場合\n",
    "        Q[s, a] = Q[s, a] + eta * (r - Q[s, a])\n",
    "        \n",
    "    else:\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gamma * Q[s_next, a_next] - Q[s, a])\n",
    "    \n",
    "    return Q\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sarsaで迷路を解くコードを実装する\n",
    "前回の方法勾配法とは異なり、価値反復法では1試行(スタートしてからゴールするまで)ではなく、１stepごとに更新を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsaで迷路を解く関数の定義、状態と行動の履歴及び更新したQを出力\n",
    "\n",
    "\n",
    "def goal_maze_rets_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0  # スタート地点\n",
    "    a = a_next = get_action(s, Q, epsilon, pi)  # 状態の行動\n",
    "    s_a_history = [[0, np.nan]]  # エージェントの行動履歴\n",
    "    \n",
    "    while(1):  # ゴールするまでループ\n",
    "        a = a_next  # 行動更新\n",
    "        \n",
    "        s_a_history[-1][1] = a\n",
    "        # 現在の状態(一番最後なのでindexは-1を見てる)に行動を代入\n",
    "        \n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "        # 次の行動を格納。s_t\n",
    "        \n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        # 次の状態を格納。\n",
    "        \n",
    "        if s_next == 8:\n",
    "            r = 1  # ゴールにたどり着いたら報酬を与える。\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            # 次の行動関数a_nextを求める。\n",
    "        \n",
    "        # 価値関数を更新\n",
    "        Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "        \n",
    "        if s_next == 8:\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "    return [s_a_history, Q]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実際に実行する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1\n",
      "1.2952378829977125\n",
      "迷路を解くのにかかったステップ数は102です\n",
      "episode: 2\n",
      "1.2450181709010382\n",
      "迷路を解くのにかかったステップ数は356です\n",
      "episode: 3\n",
      "0.017985041434554205\n",
      "迷路を解くのにかかったステップ数は6です\n",
      "episode: 4\n",
      "0.0473000577534336\n",
      "迷路を解くのにかかったステップ数は22です\n",
      "episode: 5\n",
      "0.08351910523867512\n",
      "迷路を解くのにかかったステップ数は12です\n",
      "episode: 6\n",
      "0.07902084848885543\n",
      "迷路を解くのにかかったステップ数は8です\n",
      "episode: 7\n",
      "0.0726566807193377\n",
      "迷路を解くのにかかったステップ数は6です\n",
      "episode: 8\n",
      "0.06883450839821614\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 9\n",
      "0.0677755528644422\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 10\n",
      "0.06648078075790015\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 11\n",
      "0.06494903662675153\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 12\n",
      "0.06319112856555473\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 13\n",
      "0.0623993379492363\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 14\n",
      "0.061722551619883076\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 15\n",
      "0.0609863503664555\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 16\n",
      "0.06018703239000947\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 17\n",
      "0.05932240871814534\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 18\n",
      "0.05839172552065658\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 19\n",
      "0.05739554747801301\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 20\n",
      "0.05633561676148263\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 21\n",
      "0.05521469885645386\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 22\n",
      "0.05403642375421114\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 23\n",
      "0.05280512884895361\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 24\n",
      "0.051525708118977276\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 25\n",
      "0.05020347076996434\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 26\n",
      "0.048844011412052635\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 27\n",
      "0.047453092978501976\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 28\n",
      "0.04603654292838649\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 29\n",
      "0.04460016277204393\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 30\n",
      "0.04314965058526293\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 31\n",
      "0.04169053591079397\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 32\n",
      "0.04022812626244532\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 33\n",
      "0.038767464330233814\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 34\n",
      "0.03731329492024127\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 35\n",
      "0.0358700406381508\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 36\n",
      "0.03444178533114217\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 37\n",
      "0.033032264331055605\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 38\n",
      "0.03164486058612698\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 39\n",
      "0.030282605824046627\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 40\n",
      "0.02894818595158638\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 41\n",
      "0.027643949962385117\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 42\n",
      "0.026371921692238842\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 43\n",
      "0.0251338138285368\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 44\n",
      "0.023931043645931016\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 45\n",
      "0.022764750002910228\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 46\n",
      "0.021635811192987853\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 47\n",
      "0.02054486329924421\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 48\n",
      "0.01949231875174895\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 49\n",
      "0.018478384833812367\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 50\n",
      "0.017503081925102193\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 51\n",
      "0.016566261307504826\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 52\n",
      "0.015667622393395475\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 53\n",
      "0.014806729265883667\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 54\n",
      "0.013983026446904079\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 55\n",
      "0.013195853831947102\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 56\n",
      "0.012444460750065778\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 57\n",
      "0.011728019124800149\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 58\n",
      "0.011045635726104175\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 59\n",
      "0.010396363515498441\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 60\n",
      "0.00977921209672683\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 61\n",
      "0.009193157292432197\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 62\n",
      "0.008637149873960803\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 63\n",
      "0.008110123476574471\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 64\n",
      "0.007611001736289147\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 65\n",
      "0.007138704687393416\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 66\n",
      "0.0066921544616366235\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 67\n",
      "0.006270280331198919\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 68\n",
      "0.005872023138021265\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 69\n",
      "0.005496339151983998\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 70\n",
      "0.00514220339985505\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 71\n",
      "0.004808612506006504\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 72\n",
      "0.004494587084656998\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 73\n",
      "0.004199173721934901\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 74\n",
      "0.003921446584402188\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 75\n",
      "0.003660508688913322\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 76\n",
      "0.0034154928668120865\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 77\n",
      "0.0031855624535600535\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 78\n",
      "0.0029699117329544666\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 79\n",
      "0.0027677661631619888\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 80\n",
      "0.0025783824098906116\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 81\n",
      "0.0024010482101531894\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 82\n",
      "0.0022350820882716116\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 83\n",
      "0.0020798329440244734\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 84\n",
      "0.0019346795311652176\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 85\n",
      "0.001799029842953992\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 86\n",
      "0.0016723204198324515\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 87\n",
      "0.0015540155929434363\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 88\n",
      "0.0014436066758667376\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 89\n",
      "0.0013406111156847311\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 90\n",
      "0.0012445716133238083\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 91\n",
      "0.001155055222034851\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 92\n",
      "0.0010716524318724607\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 93\n",
      "0.0009939762471029567\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 94\n",
      "0.0009216612626220533\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 95\n",
      "0.0008543627446824242\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 96\n",
      "0.0007917557205141534\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 97\n",
      "0.0007335340807759216\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 98\n",
      "0.0006794096981822539\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 99\n",
      "0.0006291115651182455\n",
      "迷路を解くのにかかったステップ数は4です\n",
      "episode: 100\n",
      "0.0005823849525731228\n",
      "迷路を解くのにかかったステップ数は4です\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eta = 0.1  # 学習率\n",
    "gamma = 0.9  # 時間割引率\n",
    "epsilon = 0.5  # e-greedy法の初期値\n",
    "v = np.nanmax(Q, axis=1)  # 状態ごとに価値の最大値を求める(ベルマン方程式)\n",
    "is_continue = True\n",
    "episode = 1\n",
    "\n",
    "while is_continue:\n",
    "    print(\"episode: \" + str(episode))\n",
    "    \n",
    "    # e-greedy法の値を徐々に小さくする\n",
    "    epsilon = epsilon / 2\n",
    "    \n",
    "    # Sarsaで迷路をとき、移動した履歴と更新したQを求める\n",
    "    [s_a_history, Q] = goal_maze_rets_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "    \n",
    "    # 状態価値の変化\n",
    "    new_v = np.nanmax(Q, axis=1)  # 状態ごとに価値の最大値を求める\n",
    "    print(np.sum(np.abs(new_v - v)))  # 状態価値の変化を出力\n",
    "    v = new_v\n",
    "    \n",
    "    print(\"迷路を解くのにかかったステップ数は\" + str(len(s_a_history) - 1) + \"です\")\n",
    "    \n",
    "    # １００ep繰り返す\n",
    "    episode = episode + 1\n",
    "    if episode > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
